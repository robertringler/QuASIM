#!/usr/bin/env python3
"""
Automated Lint & Documentation Repair Script for QuASIM
-------------------------------------------------------
This script:
  1. Fixes trailing whitespace and long lines
  2. Adds minimal docstrings to undocumented functions/classes
  3. Ensures proper file encodings and safe file access
  4. Formats code using black + isort
  5. Verifies imports and auto-installs missing modules if needed
  6. Re-runs pylint and generates a summary report

Usage:
  python scripts/auto_fix_pylint.py
"""

import argparse
import os
import re
import subprocess
from pathlib import Path

# -------------------------------
# 1. Configuration
# -------------------------------
ROOT_DIR = Path(__file__).resolve().parent.parent
MAX_LINE_LENGTH = 100
DOCSTRING_TEMPLATE_FUNC = '"""Autogenerated: Function docstring placeholder."""'
DOCSTRING_TEMPLATE_CLASS = '"""Autogenerated: Class docstring placeholder."""'

# Safety feature: Disable docstring addition by default to avoid breaking code
# Set to True to enable automatic docstring additions (use with caution)
ENABLE_AUTO_DOCSTRINGS = False

# -------------------------------
# 2. Utility Functions
# -------------------------------


def clean_trailing_whitespace(file_path: Path):
    """Remove trailing whitespace from all lines in a file."""
    content = file_path.read_text(encoding="utf-8").splitlines()
    cleaned = [line.rstrip() for line in content]
    file_path.write_text("\n".join(cleaned) + "\n", encoding="utf-8")


def ensure_docstrings(file_path: Path):
    """Add placeholder docstrings where missing.

    This function is intentionally conservative to avoid breaking code.
    It only adds docstrings to functions/classes that:
    - Have a proper definition line ending with ":"
    - Have a body on the next line that's not a docstring
    - Don't appear to be one-liners
    """
    try:
        content = file_path.read_text(encoding="utf-8").splitlines()
        new_lines = []
        i = 0
        while i < len(content):
            line = content[i]
            new_lines.append(line)

            # Match function or class definitions
            match = re.match(r"^(\s*)(def|class)\s+\w+.*:\s*$", line)
            if match and i + 1 < len(content):
                indent_str = match.group(1)
                next_line = content[i + 1]

                # Only add docstring if:
                # 1. Next line doesn't already have a docstring
                # 2. Next line is not empty or just a comment
                # 3. Next line has proper indentation (is part of the body)
                if (
                    next_line.strip()
                    and '"""' not in next_line
                    and "'''" not in next_line
                    and not next_line.strip().startswith("#")
                    and len(next_line) - len(next_line.lstrip()) > len(indent_str)
                ):
                    template = (
                        DOCSTRING_TEMPLATE_FUNC if "def" in line else DOCSTRING_TEMPLATE_CLASS
                    )
                    new_lines.append(indent_str + "    " + template)
            i += 1

        file_path.write_text("\n".join(new_lines) + "\n", encoding="utf-8")
    except Exception as e:
        # If anything goes wrong, don't modify the file
        raise RuntimeError(f"Failed to ensure docstrings in {file_path}: {e}") from e


def shorten_long_lines(file_path: Path):
    """Breaks long lines > MAX_LINE_LENGTH.

    This function is conservative and skips:
    - Lines containing URLs (http://, https://)
    - Lines in docstrings or comments that are hard to split
    """
    content = file_path.read_text(encoding="utf-8").splitlines()
    new_lines = []
    for line in content:
        # Skip lines with URLs or that are already in docstrings/comments
        has_url = re.search(r"https?://", line)

        if len(line) > MAX_LINE_LENGTH and not has_url:
            # Preserve original indentation
            indent = len(line) - len(line.lstrip())
            indent_str = line[:indent]

            # Find a good breaking point
            midpoint = line.rfind(" ", 0, MAX_LINE_LENGTH)
            if midpoint == -1 or midpoint <= indent:
                # Can't find a good break point, skip this line
                new_lines.append(line)
            else:
                # Break the line and preserve indentation
                new_lines.append(line[:midpoint] + " \\")
                new_lines.append(indent_str + "    " + line[midpoint:].lstrip())
        else:
            new_lines.append(line)
    file_path.write_text("\n".join(new_lines) + "\n", encoding="utf-8")


# -------------------------------
# 3. Main Workflow
# -------------------------------


def main():
    """Main entry point for the automated lint repair script."""
    parser = argparse.ArgumentParser(
        description="Automated lint and documentation repair for QuASIM",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                    # Run with default settings
  %(prog)s --enable-docstrings  # Enable automatic docstring addition
  %(prog)s --no-format        # Skip black/isort formatting
  %(prog)s --no-pylint        # Skip pylint report generation
        """,
    )
    parser.add_argument(
        "--enable-docstrings",
        action="store_true",
        help="Enable automatic docstring addition (disabled by default for safety)",
    )
    parser.add_argument(
        "--no-format",
        action="store_true",
        help="Skip running black and isort formatters",
    )
    parser.add_argument(
        "--no-pylint",
        action="store_true",
        help="Skip running pylint and generating report",
    )
    parser.add_argument(
        "--no-install",
        action="store_true",
        help="Skip installing missing dependencies",
    )
    args = parser.parse_args()

    print("ðŸ”§ Running automated QuASIM lint repair...")

    # Exclude certain directories from processing
    exclude_dirs = {".git", "build", "install", ".venv", "__pycache__", "node_modules"}

    python_files = []
    for f in ROOT_DIR.rglob("*.py"):
        # Skip files in excluded directories
        if not any(excluded in f.parts for excluded in exclude_dirs):
            python_files.append(f)

    print(f"Found {len(python_files)} Python files to process")

    # Apply basic fixes to all files
    for f in python_files:
        try:
            clean_trailing_whitespace(f)
            shorten_long_lines(f)
            if args.enable_docstrings:
                ensure_docstrings(f)
        except Exception as e:
            print(f"Warning: Failed to process {f}: {e}")

    # Format imports and code style
    if not args.no_format:
        print("\nðŸ“¦ Running isort and black...")
        subprocess.run(["isort", "."], check=False, cwd=ROOT_DIR)
        subprocess.run(
            ["black", ".", f"--line-length={MAX_LINE_LENGTH}"], check=False, cwd=ROOT_DIR
        )

    # Attempt to install missing modules to fix import errors
    if not args.no_install:
        print("\nðŸ“¥ Checking and installing missing dependencies...")
        required_modules = ["plotly", "markdown", "numpy"]
        for mod in required_modules:
            result = subprocess.run(
                ["pip", "install", mod, "--quiet"],
                check=False,
                capture_output=True,
                text=True,
            )
            if result.returncode != 0:
                print(f"Warning: Failed to install {mod}: {result.stderr}")
            else:
                print(f"  âœ“ {mod}")

    # Run pylint and store summary
    if not args.no_pylint:
        print("\nðŸ” Running pylint...")
        report_file = ROOT_DIR / "lint_report.txt"
        with open(report_file, "w", encoding="utf-8") as rep:
            subprocess.run(["pylint", *[str(f) for f in python_files]], stdout=rep, check=False)
        print(f"âœ… Linting complete. Report saved to: {report_file}")
    else:
        print("âœ… Lint repair complete (pylint skipped).")


if __name__ == "__main__":
    main()
